{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import codecs\n",
    "import json\n",
    "import configparser\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import h5py\n",
    "\n",
    "import spacy\n",
    "import lemminflect\n",
    "sp = spacy.load(\"en\")\n",
    "sp.Defaults.stop_words.add(\"left\")\n",
    "sp.Defaults.stop_words.add(\"right\")\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from time import localtime, strftime\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_FEATS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up config file (needs path; adapt env var if necessary); local imports\n",
    "load_dotenv()\n",
    "\n",
    "# load config file, set up paths, make project-specific imports\n",
    "config_path = os.getenv('VISCONF')\n",
    "if not config_path:\n",
    "    # try default location, if not in environment\n",
    "    default_path_to_config = '../Config/default.cfg'\n",
    "    if os.path.isfile(default_path_to_config):\n",
    "        config_path = default_path_to_config\n",
    "\n",
    "assert config_path is not None, 'You need to specify the path to the config file via environment variable VISCONF.'        \n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "with codecs.open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config.read_file(f)\n",
    "\n",
    "corpora_base = config.get('DEFAULT', 'corpora_base')\n",
    "preproc_path = config.get('DSGV-PATHS', 'preproc_path')\n",
    "dsgv_home = config.get('DSGV-PATHS', 'dsgv_home')\n",
    "\n",
    "sys.path.insert(0,dsgv_home + \"/Utils\")\n",
    "from utils import icorpus_code, plot_labelled_bb, get_image_filename, query_by_id\n",
    "from utils import plot_img_cropped, plot_img_ax, invert_dict, get_a_by_b, get_image_part\n",
    "sys.path.insert(0,dsgv_home + \"/WACs/WAC_Utils\")\n",
    "from wac_utils import create_word2den, is_relational, filter_refdf_by_filelist, filter_relational_expr\n",
    "from wac_utils import filter_X_by_filelist, make_mask_matrix, make_X_id_index, train_this_word\n",
    "from wac_utils import get_X_for_word\n",
    "\n",
    "from data_utils import load_dfs\n",
    "\n",
    "from apply_utils import apply_wac_set_matrix, logreg\n",
    "\n",
    "#sys.path.append(dsgv_home + '/Preproc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up preprocessed DataFrames. Slow!\n",
    "# These DataFrames are the result of pre-processing the original corpus data,\n",
    "# as per dsg-vision/Preprocessing/preproc.py\n",
    "\n",
    "df_names = ['refcoco_refdf', 'refcocoplus_refdf']\n",
    "df = load_dfs(preproc_path, df_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preproc_path + '/refcoco_splits.json', 'r') as f:\n",
    "    rc_splits = json.load(f)"
   ]
  },
  {
   "source": [
    "## RefCoco"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mscoco_bbdf_pattern = '/Volumes/BigData_SSD/Data/Computed/ExtractOut/vgg/mscoco_bbdf_vgg19-fc2/mscoco_bbdf_vgg19-fc2_%d.hdf5'\n",
    "# model_path_prefix = '../TrainWACs/ModelsOut/01_refcoco_vgg'\n",
    "mscoco_bbdf_pattern = '../../data/Models/ForBToma/mscoco_bbdf_rsn50-max/mscoco_bbdf_rsn50-max_%d.hdf5'\n",
    "model_path_prefix = '../../data/Models/ForBToma/01_refcoco_rsn'"
   ]
  },
  {
   "source": [
    "### Load Image Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = []\n",
    "fhs = []\n",
    "for n in range(1,8):\n",
    "    f = h5py.File(mscoco_bbdf_pattern % (n), 'r')\n",
    "    fhs.append(f)\n",
    "    das.append(da.from_array(f['img_feats'], chunks=(1000, 4106)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = da.concatenate(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(602408, 2058)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_all_test = rc_splits['testA'] + rc_splits['testB'] # rc_splits['val']  # rc_splits['testA'] + rc_splits['testB']\n",
    "X_ts = filter_X_by_filelist(X, rc_all_test)\n",
    "refdf_test = filter_refdf_by_filelist(df['refcoco_refdf'], rc_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is small enough to be fully in memory\n",
    "X_ts = X_ts[:].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meaning that I can already close the file handles\n",
    "for fh in fhs:\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2den_ts = create_word2den(refdf_test)\n",
    "X_idx_ts = make_X_id_index(X_ts)\n",
    "mask_matrix_ts = make_mask_matrix(X_ts, X_idx_ts, word2den_ts, word2den_ts.keys())"
   ]
  },
  {
   "source": [
    "### Load WACs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp2indseq(w2i, exp):\n",
    "    return [word2ind[w] for w in exp.split() if w in word2ind] #the list of indices for each \"word\" in exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageid2rows(idx, ic, ii):\n",
    "    '''return all regions that belong to an image, as indices into X (via idx)'''\n",
    "    # or should this be a separate dictionary?\n",
    "    return [v for k,v in idx.items() if k[0] == ic and k[1] == ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path_prefix + '.hdf5', 'r') as f:\n",
    "    wacs = f['wac_weights'][:]   # slice, to actually read into memory (as ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(model_path_prefix + '.json', 'r') as f:\n",
    "    modelpars, wordlist = json.load(f)"
   ]
  },
  {
   "source": [
    "### Apply all WACs to all regions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_applied = apply_wac_set_matrix(X_ts[:, ID_FEATS:], wacs.T, net=logreg) #applies all wac and returns a matrix of results, rows are entities and columns are words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind = {w[0]:n for n,w in enumerate(wordlist)} #creates dictionary from word to its index in the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_corpus(rfdf, X, idx, w2i, all_applied):\n",
    "    out = []\n",
    "    for n, row in rfdf.iterrows():\n",
    "        ic, ii, ri, refexp = row['i_corpus image_id region_id refexp'.split()]\n",
    "        #if is_relational(refexp)\n",
    "        all_regs = imageid2rows(idx, ic, ii) #all regions that belong to an image\n",
    "        this_exp_seq = exp2indseq(w2i, refexp) #the indices in the wordlist for each word in the referring expression\n",
    "        all_regs_applied = np.prod(all_applied[all_regs][:, this_exp_seq], axis=1) #the product for the words in the ref exp\n",
    "        regions_ranked = np.array(all_regs)[np.argsort(all_regs_applied)[::-1]] # ranked list of region products \n",
    "        try:\n",
    "            this_rank = np.where(X[regions_ranked][:, ID_FEATS-1] == ri)[0][0] # returns highest ranked region\n",
    "        except:\n",
    "            print(ic, ii, ri, '\\t region not in X?')    #unless it's not there, then they put this\n",
    "        out_of = len(all_regs)  # the number of regions\n",
    "        out.append((ic, ii, ri, refexp, is_relational(refexp), this_rank, out_of,\n",
    "                    len(this_exp_seq) / len(refexp.split()) ))  #add this to the output, as well as the % of words in the vocab\n",
    "    return pd.DataFrame(out, columns='i_corpus image_id region_id refexp is_rel rank n_obj perc_cov'.split())   #return it all as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependency parse each refexp to make generation a bit easier hopefully\n",
    "refdf_test[\"DepParse\"] = refdf_test.apply(lambda row: sp(row.refexp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will go through and create some sort of representation of every referring expression (and hopefully also every word?) per picture\n",
    "ref_dict = {}\n",
    "for i in refdf_test[\"image_id\"].unique():\n",
    "    ref_dict[i] = {refdf_test[\"refexp\"][j] : j for j in refdf_test[refdf_test[\"image_id\"] == i].index}\n",
    "ref_vocab = defaultdict(set)\n",
    "for k, v in ref_dict.items():\n",
    "    for exp in v:\n",
    "        for word in refdf_test.loc[v[exp]][\"DepParse\"]:\n",
    "            if word.text in word2ind and not word.is_stop:\n",
    "                ref_vocab[k].add(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_nps(image_id):\n",
    "    nps = set()\n",
    "    for k, v in ref_dict[image_id].items():\n",
    "        for chunk in refdf_test.loc[v][\"DepParse\"].noun_chunks:\n",
    "            if chunk.root.text in word2ind and not chunk.root.is_stop:\n",
    "                nps.add(\" \".join([token._.inflect(\"NN\") if token == chunk.root else token.text for token in chunk if token.text != \"the\"]))\n",
    "    return nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = list(refdf_test.image_id.unique())\n",
    "ref_dict_per_id = [ref_dict[x] for x in image_ids]\n",
    "ref_voc_per_id = [ref_vocab[x] for x in image_ids]\n",
    "good_nps_per_id = [get_good_nps(x) for x in image_ids]\n",
    "im_ref_df = pd.DataFrame({\"image_id\": image_ids, \"ref_exps\": ref_dict_per_id, \"vocab\": ref_voc_per_id, \"NPs\": good_nps_per_id}).set_index(\"image_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   ref_exps  \\\n",
       "image_id                                                      \n",
       "581563    {'lower left corner darkness': 0, 'bpttom left...   \n",
       "581518    {'top donut': 8, 'top of donuts': 7, 'donut wc...   \n",
       "581346    {'left zebra butt': 13, 'zebra on the left': 1...   \n",
       "581282    {'person bottom left': 18, 'left black shirt':...   \n",
       "580668    {'man on right': 20, 'right man': 21, 'man sit...   \n",
       "\n",
       "                                                      vocab  \\\n",
       "image_id                                                      \n",
       "581563                    {dark, corner, lower, black, van}   \n",
       "581518                   {second, donut, middle, sprinkles}   \n",
       "581346                                        {zebra, butt}   \n",
       "581282                               {shirt, person, black}   \n",
       "580668    {man, person, yellow, car, white, bench, sitti...   \n",
       "\n",
       "                                                        NPs  \n",
       "image_id                                                     \n",
       "581563                                          {black van}  \n",
       "581518           {sprinkle, donut, top donut, middle donut}  \n",
       "581346    {zebra, right zebra butt, zebra right butt, ze...  \n",
       "581282                                        {black shirt}  \n",
       "580668    {left car, man, person, right man, bench, whit...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ref_exps</th>\n      <th>vocab</th>\n      <th>NPs</th>\n    </tr>\n    <tr>\n      <th>image_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>581563</th>\n      <td>{'lower left corner darkness': 0, 'bpttom left...</td>\n      <td>{dark, corner, lower, black, van}</td>\n      <td>{black van}</td>\n    </tr>\n    <tr>\n      <th>581518</th>\n      <td>{'top donut': 8, 'top of donuts': 7, 'donut wc...</td>\n      <td>{second, donut, middle, sprinkles}</td>\n      <td>{sprinkle, donut, top donut, middle donut}</td>\n    </tr>\n    <tr>\n      <th>581346</th>\n      <td>{'left zebra butt': 13, 'zebra on the left': 1...</td>\n      <td>{zebra, butt}</td>\n      <td>{zebra, right zebra butt, zebra right butt, ze...</td>\n    </tr>\n    <tr>\n      <th>581282</th>\n      <td>{'person bottom left': 18, 'left black shirt':...</td>\n      <td>{shirt, person, black}</td>\n      <td>{black shirt}</td>\n    </tr>\n    <tr>\n      <th>580668</th>\n      <td>{'man on right': 20, 'right man': 21, 'man sit...</td>\n      <td>{man, person, yellow, car, white, bench, sitti...</td>\n      <td>{left car, man, person, right man, bench, whit...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "im_ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nps = set().union(*good_nps_per_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_exp(rfdf, idx: \"\"\"image id\"\"\", n: \"\"\"maximum number of statements per image\"\"\"):\n",
    "    #this function will generate true sentences containing refexp for a given image\n",
    "    truths = []\n",
    "    eligible_NPs = list(rfdf.loc[idx][\"NPs\"])\n",
    "    random.shuffle(eligible_NPs)\n",
    "    while len(truths) < n:\n",
    "        if not eligible_NPs:\n",
    "            break\n",
    "        np = eligible_NPs.pop()\n",
    "        if np.startswith(('a','e','i','o','u')):\n",
    "            article = \"an\"\n",
    "        else:\n",
    "            article = \"a\"\n",
    "        truths.append(f\"There is {article} {np}.\")\n",
    "    return truths\n",
    "\n",
    "\n",
    "def generate_false_exp(rfdf, every_np, idx: \"\"\"image id\"\"\", n: \"\"\"number of statements per image\"\"\"):\n",
    "    #this function will generate false sentences (hopefully) for a given image\n",
    "    lies = []\n",
    "    eligible_NPs = list(every_np)\n",
    "    random.shuffle(eligible_NPs)\n",
    "    for np in eligible_NPs:\n",
    "        if len(lies) >= n:\n",
    "            break\n",
    "        elif any([word in rfdf.loc[idx][\"vocab\"] for word in np.split()]):\n",
    "            continue\n",
    "        else:\n",
    "            if np.startswith(('a','e','i','o','u')):\n",
    "                article = \"an\"\n",
    "            else:\n",
    "                article = \"a\"\n",
    "            lies.append(f\"There is {article} {np}.\")\n",
    "    return lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [generate_true_exp(im_ref_df, x, 2) for x in im_ref_df.index.to_series()]\n",
    "neg = [generate_false_exp(im_ref_df, all_nps, x, 2) for x in im_ref_df.index.to_series()]\n",
    "im_ref_df[\"Positives\"] = pos\n",
    "im_ref_df[\"Negatives\"] = neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   ref_exps  \\\n",
       "image_id                                                      \n",
       "581563    {'lower left corner darkness': 0, 'bpttom left...   \n",
       "581518    {'top donut': 8, 'top of donuts': 7, 'donut wc...   \n",
       "581346    {'left zebra butt': 13, 'zebra on the left': 1...   \n",
       "581282    {'person bottom left': 18, 'left black shirt':...   \n",
       "580668    {'man on right': 20, 'right man': 21, 'man sit...   \n",
       "\n",
       "                                                      vocab  \\\n",
       "image_id                                                      \n",
       "581563                    {dark, corner, lower, black, van}   \n",
       "581518                   {second, donut, middle, sprinkles}   \n",
       "581346                                        {zebra, butt}   \n",
       "581282                               {shirt, person, black}   \n",
       "580668    {man, person, yellow, car, white, bench, sitti...   \n",
       "\n",
       "                                                        NPs  \\\n",
       "image_id                                                      \n",
       "581563                                          {black van}   \n",
       "581518           {sprinkle, donut, top donut, middle donut}   \n",
       "581346    {zebra, right zebra butt, zebra right butt, ze...   \n",
       "581282                                        {black shirt}   \n",
       "580668    {left car, man, person, right man, bench, whit...   \n",
       "\n",
       "                                                  Positives  \\\n",
       "image_id                                                      \n",
       "581563                              [There is a black van.]   \n",
       "581518           [There is a top donut., There is a donut.]   \n",
       "581346    [There is a zebra right butt., There is a righ...   \n",
       "581282                            [There is a black shirt.]   \n",
       "580668            [There is a left car., There is a bench.]   \n",
       "\n",
       "                                                  Negatives  \n",
       "image_id                                                     \n",
       "581563                [There is a screen., There is a cow.]  \n",
       "581518    [There is a rightmost person., There is a dark...  \n",
       "581346    [There is a center person., There is an orange...  \n",
       "581282      [There is a red chair., There is a front bird.]  \n",
       "580668    [There is a brown teddy bear., There is a red ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ref_exps</th>\n      <th>vocab</th>\n      <th>NPs</th>\n      <th>Positives</th>\n      <th>Negatives</th>\n    </tr>\n    <tr>\n      <th>image_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>581563</th>\n      <td>{'lower left corner darkness': 0, 'bpttom left...</td>\n      <td>{dark, corner, lower, black, van}</td>\n      <td>{black van}</td>\n      <td>[There is a black van.]</td>\n      <td>[There is a screen., There is a cow.]</td>\n    </tr>\n    <tr>\n      <th>581518</th>\n      <td>{'top donut': 8, 'top of donuts': 7, 'donut wc...</td>\n      <td>{second, donut, middle, sprinkles}</td>\n      <td>{sprinkle, donut, top donut, middle donut}</td>\n      <td>[There is a top donut., There is a donut.]</td>\n      <td>[There is a rightmost person., There is a dark...</td>\n    </tr>\n    <tr>\n      <th>581346</th>\n      <td>{'left zebra butt': 13, 'zebra on the left': 1...</td>\n      <td>{zebra, butt}</td>\n      <td>{zebra, right zebra butt, zebra right butt, ze...</td>\n      <td>[There is a zebra right butt., There is a righ...</td>\n      <td>[There is a center person., There is an orange...</td>\n    </tr>\n    <tr>\n      <th>581282</th>\n      <td>{'person bottom left': 18, 'left black shirt':...</td>\n      <td>{shirt, person, black}</td>\n      <td>{black shirt}</td>\n      <td>[There is a black shirt.]</td>\n      <td>[There is a red chair., There is a front bird.]</td>\n    </tr>\n    <tr>\n      <th>580668</th>\n      <td>{'man on right': 20, 'right man': 21, 'man sit...</td>\n      <td>{man, person, yellow, car, white, bench, sitti...</td>\n      <td>{left car, man, person, right man, bench, whit...</td>\n      <td>[There is a left car., There is a bench.]</td>\n      <td>[There is a brown teddy bear., There is a red ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "im_ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eval_corpus(rfdf, X, idz, w2i, all_applied):\n",
    "    pass\n",
    "    # go through and get classifications for each bounding box -- ideally for a specific expression but maybe for all of them?\n",
    "    # for each picture (and each expression? or just the one of interest for that pic) create a set of bounding box entities described by that expression (if boolean) or a list of probabilities\n",
    "    # then use the n for quantification that you're looking at and either produce a boolean based on whether there are at least n entities in the set, or use the prob_at_least function from semparse to assess the probability of there being at least n entities based on the probabilities for each entity\n",
    "    #produce a new dataframe with pictures, expressions, and booleans/probabilities (as well as the perc_cov and is_rel values as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf = eval_corpus(refdf_test, X_ts, X_idx_ts, word2ind, all_applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(outdf['rank'] == 0) / len(outdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(outdf['rank'] < 3) / len(outdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_outdf_(subdf):\n",
    "    print('accuracy @1: {:.2}'.format(np.sum(subdf['rank'] == 0) / len(subdf))) #accuracy at correct entity being the top one\n",
    "    print('accuracy @3: {:.2}'.format(np.sum(subdf['rank'] < 3) / len(subdf))) #accuracy at correct entity being in top three\n",
    "    print('mean reciprocal rank: {:.2}'.format(np.mean(1 / (subdf['rank'] + 1)))) #1.0 would be always first, 0.0 is never first\n",
    "    print('random baseline: {:.3}'.format(1 / np.mean(subdf['n_obj']))) #random baseline for comparison\n",
    "\n",
    "\n",
    "def score_outdf(outdf):\n",
    "    print('** full')\n",
    "    score_outdf_(outdf)\n",
    "    print('** NR')  # omits relative ones\n",
    "    score_outdf_(outdf[outdf['is_rel'] == False])\n",
    "    print('** NR, cov > 0.5')   #omits ones with more than half the words not in our classifiers\n",
    "    score_outdf_(outdf[(outdf['is_rel'] == False) & (outdf['perc_cov'] >= 0.5)])"
   ]
  }
 ]
}